{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embarrasingly parallel date operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "each row is processed independently\n",
    "\n",
    "I want to calculate the number of days to and after the next holiday. As I am new to python I am unsure how to perform such a calculation efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import datetime as DT\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load dates and holidays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "datesFrame = pd.read_csv('myDates.csv')\n",
    "datesFrame.myDates = pd.to_datetime(datesFrame.myDates)\n",
    "\n",
    "holidays = pd.read_csv('holidays.csv')\n",
    "holidays.day = pd.to_datetime(holidays.day)\n",
    "holidays.type = holidays.type.astype(\"category\")\n",
    "holidays.name = holidays.name.astype(\"category\")\n",
    "\n",
    "holidays = holidays[holidays.apply(lambda x: (x.type == 'National holiday'), axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_nearest_date(dates, pivot):\n",
    "    nearest = min(dates, key=lambda x: abs(x - pivot))\n",
    "    difference = abs(nearest - pivot)\n",
    "    return difference / np.timedelta64(1, 'D')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## approach 1 - too slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datesFrameSmall= datesFrame[: 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "function took 114.090 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>myDates</th>\n",
       "      <th>daysBeforeHoliday</th>\n",
       "      <th>daysAfterHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014-09-01</td>\n",
       "      <td>17.0</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2014-01-18</td>\n",
       "      <td>12.0</td>\n",
       "      <td>93.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>8.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2014-01-23</td>\n",
       "      <td>17.0</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2014-12-01</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>54.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2014-04-06</td>\n",
       "      <td>90.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     myDates  daysBeforeHoliday  daysAfterHoliday\n",
       "0 2014-09-01               17.0              55.0\n",
       "1 2014-03-01               54.0              51.0\n",
       "2 2014-03-01               54.0              51.0\n",
       "3 2014-01-18               12.0              93.0\n",
       "4 2014-01-14                8.0              97.0\n",
       "5 2014-01-23               17.0              88.0\n",
       "6 2014-12-01               30.0               7.0\n",
       "7 2014-03-01               54.0              51.0\n",
       "8 2014-03-01               54.0              51.0\n",
       "9 2014-04-06               90.0              15.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "datesFrameSmall['daysBeforeHoliday'] = datesFrameSmall.myDates.apply(lambda x: get_nearest_date(holidays.day[holidays.day < x], x))\n",
    "datesFrameSmall['daysAfterHoliday']  =  datesFrameSmall.myDates.apply(lambda x: get_nearest_date(holidays.day[holidays.day > x], x))\n",
    "time2 = time.time()\n",
    "print ('function took %0.3f ms' % ((time2-time1)*1000.0))\n",
    "datesFrameSmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# disabled - takes too long\n",
    "#time1 = time.time()\n",
    "#datesFrame['daysBeforeHoliday'] = datesFrame.myDates.apply(lambda x: get_nearest_date(holidays.day[holidays.day < x], x))\n",
    "#datesFrame['daysAfterHoliday']  =  datesFrame.myDates.apply(lambda x: get_nearest_date(holidays.day[holidays.day > x], x))\n",
    "#time2 = time.time()\n",
    "#print ('function took %0.3f ms' % ((time2-time1)*1000.0))\n",
    "#datesFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## approach 2 - noReturnValues  -> parallel processing + cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import datetime as DT\n",
    "import skutils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "import time\n",
    "## strange - > have to re import all the things for cython. \n",
    "datesFrame = pd.read_csv('myDates.csv')\n",
    "datesFrame.myDates = pd.to_datetime(datesFrame.myDates)\n",
    "\n",
    "holidays = pd.read_csv('holidays.csv')\n",
    "holidays.day = pd.to_datetime(holidays.day)\n",
    "holidays.type = holidays.type.astype(\"category\")\n",
    "holidays.name = holidays.name.astype(\"category\")\n",
    "\n",
    "holidays = holidays[holidays.apply(lambda x: (x.type == 'National holiday'), axis=1)]\n",
    "\n",
    "def get_nearest_date(dates, pivot):\n",
    "    nearest = min(dates, key=lambda x: abs(x - pivot))\n",
    "    difference = abs(nearest - pivot)\n",
    "    return difference / np.timedelta64(1, 'D')\n",
    "################\n",
    "import multiprocessing\n",
    "num_cpus = multiprocessing.cpu_count()\n",
    "\n",
    "time1 = time.time()\n",
    "n_entries = datesFrame.shape[0]\n",
    "n_entrie_perfold = round(n_entries / num_cpus)\n",
    "folds = [datesFrame[start:start+n_entrie_perfold] for start in range(0, n_entries + 1, n_entrie_perfold)]\n",
    "\n",
    "def process_fold(df_per_fold):\n",
    "    df_per_fold['daysBeforeHoliday'] = df_per_fold.myDates.apply(lambda x: get_nearest_date(holidays.day[holidays.day < x], x))\n",
    "    df_per_fold['daysAfterHoliday'] = df_per_fold.myDates.apply(lambda x: get_nearest_date(holidays.day[holidays.day > x], x))\n",
    "    return df_per_fold\n",
    "    \n",
    "pool = multiprocessing.Pool(processes=num_cpus)  \n",
    "pool.map(process_fold, folds)\n",
    "\n",
    "time2 = time.time()\n",
    "print ('function took %0.3f ms' % ((time2-time1)*1000.0))\n",
    "datesFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to parallelize well. Still it is not really \"quick\". Strange that cython does require everything in a single jupyter cell. \n",
    "\n",
    "However, there is no output in the datesframe. What am I doing wrong here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## approach 3 - parallelApply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    with Pool(cpu_count()) as p:\n",
    "        ret_list = p.map(func, [group for name, group in dfGrouped])\n",
    "    return pandas.concat(ret_list)\n",
    "\n",
    "def apply_row_foo(input_df):\n",
    "    return input_df.apply((row_foo), axis=1)\n",
    "\n",
    "n_chunks = 10\n",
    "\n",
    "grouped = df.groupby(df.index // n_chunks)\n",
    "applyParallel(grouped, apply_row_foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only for grouped data --> how to port to rows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel version: \n",
      "    a  b   c\n",
      "g1  6  4  10\n",
      "g1  2  5   7\n",
      "g2  2  6   8\n",
      "regular version: \n",
      "    a  b   c\n",
      "g1  6  4  10\n",
      "g1  2  5   7\n",
      "g2  2  6   8\n"
     ]
    }
   ],
   "source": [
    "# from http://stackoverflow.com/questions/26187759/parallelize-apply-after-pandas-groupby/29281494#29281494\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "def tmpFunc(df):\n",
    "    df['c'] = df.a + df.b\n",
    "    return df\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "df = pd.DataFrame({'a': [6, 2, 2], 'b': [4, 5, 6]},index= ['g1', 'g1', 'g2'])\n",
    "print ('parallel version: ')\n",
    "print( applyParallel(df.groupby(df.index), tmpFunc))\n",
    "\n",
    "print ('regular version: ')\n",
    "print (df.groupby(df.index).apply(tmpFunc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "here my try to port it. But so far I do not know how to pass both 2 parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parallel version: \n"
     ]
    },
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x105b74300, file \"/usr...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105b74300, file \"/usr...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/traitlets-4.2.2-py3.5.egg/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-09-03T17:17:40.373104', 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'session': '220818B99B4449D589C6EEE455A037F3', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'220818B99B4449D589C6EEE455A037F3']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-09-03T17:17:40.373104', 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'session': '220818B99B4449D589C6EEE455A037F3', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'220818B99B4449D589C6EEE455A037F3'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-09-03T17:17:40.373104', 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'session': '220818B99B4449D589C6EEE455A037F3', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))',), **kwargs={'silent': False, 'store_history': True})\n    493             )\n    494         self.payload_manager.write_payload(payload)\n    495 \n    496     def run_cell(self, *args, **kwargs):\n    497         self._last_traceback = None\n--> 498         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))',)\n        kwargs = {'silent': False, 'store_history': True}\n    499 \n    500     def _showtraceback(self, etype, evalue, stb):\n    501         # try to preserve ordering of tracebacks and print statements\n    502         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Import object>, <_ast.FunctionDef object>, <_ast.FunctionDef object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-28-24c5f514da83>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 10c5bb400, execution_..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x107210780, file \"<ipython-input-28-24c5f514da83>\", line 14>\n        result = <ExecutionResult object at 10c5bb400, execution_..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x107210780, file \"<ipython-input-28-24c5f514da83>\", line 14>, result=<ExecutionResult object at 10c5bb400, execution_..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x107210780, file \"<ipython-input-28-24c5f514da83>\", line 14>\n        self.user_global_ns = {'DT': <module 'datetime' from '/usr/local/Cellar/pytho...ramework/Versions/3.5/lib/python3.5/datetime.py'>, 'In': ['', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'Cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', \"get_ipython().magic('load_ext Cython')\", 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%mat...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"impo...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', r\"get_ipython().run_cell_magic('cython', '', 'date...a x: (x.type == \\'National holiday\\'), axis=1)]')\", \"datesFrame = pd.read_csv('myDates.csv')\\ndatesFra...ambda x: (x.type == 'National holiday'), axis=1)]\", 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"def ...n    return difference / np.timedelta64(1, \\'D\\')\")', \"get_ipython().magic('load_ext Cython')\", \"import pandas as pd\\nimport numpy as np\\nimport ma...pyplot as plt\\nplt.style.use('ggplot')\\nimport time\", \"datesFrame = pd.read_csv('myDates.csv')\\ndatesFra...ambda x: (x.type == 'National holiday'), axis=1)]\", \"def get_nearest_date(dates, pivot):\\n    nearest ...t)\\n    return difference / np.timedelta64(1, 'D')\", 'datesFrameSmall= datesFrame[: 10]', \"time1 = time.time()\\ndatesFrameSmall['daysBeforeH....3f ms' % ((time2-time1)*1000.0))\\ndatesFrameSmall\", \"# disabled - takes too long\\n#time1 = time.time()...k %0.3f ms' % ((time2-time1)*1000.0))\\n#datesFrame\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", ...], 'Out': {15:      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, 20:           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], 25: <pandas.core.groupby.DataFrameGroupBy object>}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': <pandas.core.groupby.DataFrameGroupBy object>, '_15':      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, '_20':           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], '_25': <pandas.core.groupby.DataFrameGroupBy object>, '__':           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], '___':      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, ...}\n        self.user_ns = {'DT': <module 'datetime' from '/usr/local/Cellar/pytho...ramework/Versions/3.5/lib/python3.5/datetime.py'>, 'In': ['', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'Cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', \"get_ipython().magic('load_ext Cython')\", 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%mat...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"impo...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', r\"get_ipython().run_cell_magic('cython', '', 'date...a x: (x.type == \\'National holiday\\'), axis=1)]')\", \"datesFrame = pd.read_csv('myDates.csv')\\ndatesFra...ambda x: (x.type == 'National holiday'), axis=1)]\", 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"def ...n    return difference / np.timedelta64(1, \\'D\\')\")', \"get_ipython().magic('load_ext Cython')\", \"import pandas as pd\\nimport numpy as np\\nimport ma...pyplot as plt\\nplt.style.use('ggplot')\\nimport time\", \"datesFrame = pd.read_csv('myDates.csv')\\ndatesFra...ambda x: (x.type == 'National holiday'), axis=1)]\", \"def get_nearest_date(dates, pivot):\\n    nearest ...t)\\n    return difference / np.timedelta64(1, 'D')\", 'datesFrameSmall= datesFrame[: 10]', \"time1 = time.time()\\ndatesFrameSmall['daysBeforeH....3f ms' % ((time2-time1)*1000.0))\\ndatesFrameSmall\", \"# disabled - takes too long\\n#time1 = time.time()...k %0.3f ms' % ((time2-time1)*1000.0))\\n#datesFrame\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", ...], 'Out': {15:      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, 20:           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], 25: <pandas.core.groupby.DataFrameGroupBy object>}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': <pandas.core.groupby.DataFrameGroupBy object>, '_15':      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, '_20':           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], '_25': <pandas.core.groupby.DataFrameGroupBy object>, '__':           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], '___':      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Users/geoHeil/Dropbox/masterThesis/thesis/researchCode/python/TMA/<ipython-input-28-24c5f514da83> in <module>()\n      9 def applyParallel(dfGrouped, func):\n     10     retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n     11     return pd.concat(retLst)\n     12 \n     13 print ('parallel version: ')\n---> 14 print( applyParallel(datesFrame.groupby(datesFrame.index), get_nearest_dateParallel))\n     15 \n     16 \n     17 \n     18 \n\n...........................................................................\n/Users/geoHeil/Dropbox/masterThesis/thesis/researchCode/python/TMA/<ipython-input-28-24c5f514da83> in applyParallel(dfGrouped=<pandas.core.groupby.DataFrameGroupBy object>, func=<function get_nearest_dateParallel>)\n      5     nearest = min(dates, key=lambda x: abs(x - pivot))\n      6     difference = abs(nearest - pivot)\n      7     return difference / np.timedelta64(1, 'D')\n      8 \n      9 def applyParallel(dfGrouped, func):\n---> 10     retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n     11     return pd.concat(retLst)\n     12 \n     13 print ('parallel version: ')\n     14 print( applyParallel(datesFrame.groupby(datesFrame.index), get_nearest_dateParallel))\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object applyParallel.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Sat Sep  3 17:17:40 2016\nPID: 4494                Python 3.5.2: /usr/local/opt/python3/bin/python3.5\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function get_nearest_dateParallel>, (     myDates\n0 2014-09-01,), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function get_nearest_dateParallel>\n        args = (     myDates\n0 2014-09-01,)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\nTypeError: get_nearest_dateParallel() missing 1 required positional argument: 'pivot'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.5/site-packages/joblib/_parallel_backends.py\", line 340, in __call__\n    return self.func(*args, **kwargs)\n  File \"/usr/local/lib/python3.5/site-packages/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/usr/local/lib/python3.5/site-packages/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\nTypeError: get_nearest_dateParallel() missing 1 required positional argument: 'pivot'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/usr/local/lib/python3.5/site-packages/joblib/_parallel_backends.py\", line 349, in __call__\n    raise TransportableException(text, e_type)\njoblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Sat Sep  3 17:17:40 2016\nPID: 4494                Python 3.5.2: /usr/local/opt/python3/bin/python3.5\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function get_nearest_dateParallel>, (     myDates\n0 2014-09-01,), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function get_nearest_dateParallel>\n        args = (     myDates\n0 2014-09-01,)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\nTypeError: get_nearest_dateParallel() missing 1 required positional argument: 'pivot'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    681\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m'timeout'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    607\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 608\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Sat Sep  3 17:17:40 2016\nPID: 4494                Python 3.5.2: /usr/local/opt/python3/bin/python3.5\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function get_nearest_dateParallel>, (     myDates\n0 2014-09-01,), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function get_nearest_dateParallel>\n        args = (     myDates\n0 2014-09-01,)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\nTypeError: get_nearest_dateParallel() missing 1 required positional argument: 'pivot'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-24c5f514da83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'parallel version: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mapplyParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatesFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatesFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_nearest_dateParallel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-24c5f514da83>\u001b[0m in \u001b[0;36mapplyParallel\u001b[0;34m(dfGrouped, func)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapplyParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdfGrouped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mretLst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfGrouped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretLst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    766\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 768\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    769\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    179         sys.exit(msg)\n    180     main_globals = sys.modules[\"__main__\"].__dict__\n    181     if alter_argv:\n    182         sys.argv[0] = mod_spec.origin\n    183     return _run_code(code, main_globals, None,\n--> 184                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py')\n    185 \n    186 def run_module(mod_name, init_globals=None,\n    187                run_name=None, alter_sys=False):\n    188     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/usr/local/Cellar/python3/3.5.2_1/Frameworks/Python.framework/Versions/3.5/lib/python3.5/runpy.py in _run_code(code=<code object <module> at 0x105b74300, file \"/usr...3.5/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x105b74300, file \"/usr...3.5/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__builtins__': <module 'builtins' (built-in)>, '__cached__': '/usr/local/lib/python3.5/site-packages/ipykernel/__pycache__/__main__.cpython-35.pyc', '__doc__': None, '__file__': '/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.5/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py in <module>()\n      1 \n      2 \n----> 3 \n      4 if __name__ == '__main__':\n      5     from ipykernel import kernelapp as app\n      6     app.launch_new_instance()\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/traitlets-4.2.2-py3.5.egg/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    591         \n    592         If a global instance already exists, this reinitializes and starts it\n    593         \"\"\"\n    594         app = cls.instance(**kwargs)\n    595         app.initialize(argv)\n--> 596         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    597 \n    598 #-----------------------------------------------------------------------------\n    599 # utility functions, for convenience\n    600 #-----------------------------------------------------------------------------\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    469             return self.subapp.start()\n    470         if self.poller is not None:\n    471             self.poller.start()\n    472         self.kernel.start()\n    473         try:\n--> 474             ioloop.IOLoop.instance().start()\n    475         except KeyboardInterrupt:\n    476             pass\n    477 \n    478 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    157             PollIOLoop.configure(ZMQIOLoop)\n    158         return PollIOLoop.current(*args, **kwargs)\n    159     \n    160     def start(self):\n    161         try:\n--> 162             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    163         except ZMQError as e:\n    164             if e.errno == ETERM:\n    165                 # quietly return on ETERM\n    166                 pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    882                 self._events.update(event_pairs)\n    883                 while self._events:\n    884                     fd, events = self._events.popitem()\n    885                     try:\n    886                         fd_obj, handler_func = self._handlers[fd]\n--> 887                         handler_func(fd_obj, events)\n        handler_func = <function wrap.<locals>.null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    888                     except (OSError, IOError) as e:\n    889                         if errno_from_exception(e) == errno.EPIPE:\n    890                             # Happens when the client closes the connection\n    891                             pass\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    270         # Fast path when there are no active contexts.\n    271         def null_wrapper(*args, **kwargs):\n    272             try:\n    273                 current_state = _state.contexts\n    274                 _state.contexts = cap_contexts[0]\n--> 275                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    276             finally:\n    277                 _state.contexts = current_state\n    278         null_wrapper._wrapped = True\n    279         return null_wrapper\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    271         if self.control_stream:\n    272             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    273 \n    274         def make_dispatcher(stream):\n    275             def dispatcher(msg):\n--> 276                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    277             return dispatcher\n    278 \n    279         for s in self.shell_streams:\n    280             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-09-03T17:17:40.373104', 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'session': '220818B99B4449D589C6EEE455A037F3', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'parent_header': {}})\n    223             self.log.error(\"UNKNOWN MESSAGE TYPE: %r\", msg_type)\n    224         else:\n    225             self.log.debug(\"%s: %s\", msg_type, msg)\n    226             self.pre_handler_hook()\n    227             try:\n--> 228                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'220818B99B4449D589C6EEE455A037F3']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-09-03T17:17:40.373104', 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'session': '220818B99B4449D589C6EEE455A037F3', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'parent_header': {}}\n    229             except Exception:\n    230                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    231             finally:\n    232                 self.post_handler_hook()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'220818B99B4449D589C6EEE455A037F3'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': '2016-09-03T17:17:40.373104', 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'session': '220818B99B4449D589C6EEE455A037F3', 'username': 'username', 'version': '5.0'}, 'metadata': {}, 'msg_id': '72DDB024E68D492BAB4CF4741C36F235', 'msg_type': 'execute_request', 'parent_header': {}})\n    385         if not silent:\n    386             self.execution_count += 1\n    387             self._publish_execute_input(code, parent, self.execution_count)\n    388 \n    389         reply_content = self.do_execute(code, silent, store_history,\n--> 390                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    391 \n    392         # Flush output before sending the reply.\n    393         sys.stdout.flush()\n    394         sys.stderr.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))'\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))',), **kwargs={'silent': False, 'store_history': True})\n    493             )\n    494         self.payload_manager.write_payload(payload)\n    495 \n    496     def run_cell(self, *args, **kwargs):\n    497         self._last_traceback = None\n--> 498         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))',)\n        kwargs = {'silent': False, 'store_history': True}\n    499 \n    500     def _showtraceback(self, etype, evalue, stb):\n    501         # try to preserve ordering of tracebacks and print statements\n    502         sys.stdout.flush()\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='from joblib import Parallel, delayed\\nimport mult...pby(datesFrame.index), get_nearest_dateParallel))', store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.ImportFrom object>, <_ast.Import object>, <_ast.FunctionDef object>, <_ast.FunctionDef object>, <_ast.Expr object>, <_ast.Expr object>], cell_name='<ipython-input-28-24c5f514da83>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 10c5bb400, execution_..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x107210780, file \"<ipython-input-28-24c5f514da83>\", line 14>\n        result = <ExecutionResult object at 10c5bb400, execution_..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x107210780, file \"<ipython-input-28-24c5f514da83>\", line 14>, result=<ExecutionResult object at 10c5bb400, execution_..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x107210780, file \"<ipython-input-28-24c5f514da83>\", line 14>\n        self.user_global_ns = {'DT': <module 'datetime' from '/usr/local/Cellar/pytho...ramework/Versions/3.5/lib/python3.5/datetime.py'>, 'In': ['', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'Cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', \"get_ipython().magic('load_ext Cython')\", 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%mat...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"impo...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', r\"get_ipython().run_cell_magic('cython', '', 'date...a x: (x.type == \\'National holiday\\'), axis=1)]')\", \"datesFrame = pd.read_csv('myDates.csv')\\ndatesFra...ambda x: (x.type == 'National holiday'), axis=1)]\", 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"def ...n    return difference / np.timedelta64(1, \\'D\\')\")', \"get_ipython().magic('load_ext Cython')\", \"import pandas as pd\\nimport numpy as np\\nimport ma...pyplot as plt\\nplt.style.use('ggplot')\\nimport time\", \"datesFrame = pd.read_csv('myDates.csv')\\ndatesFra...ambda x: (x.type == 'National holiday'), axis=1)]\", \"def get_nearest_date(dates, pivot):\\n    nearest ...t)\\n    return difference / np.timedelta64(1, 'D')\", 'datesFrameSmall= datesFrame[: 10]', \"time1 = time.time()\\ndatesFrameSmall['daysBeforeH....3f ms' % ((time2-time1)*1000.0))\\ndatesFrameSmall\", \"# disabled - takes too long\\n#time1 = time.time()...k %0.3f ms' % ((time2-time1)*1000.0))\\n#datesFrame\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", ...], 'Out': {15:      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, 20:           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], 25: <pandas.core.groupby.DataFrameGroupBy object>}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': <pandas.core.groupby.DataFrameGroupBy object>, '_15':      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, '_20':           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], '_25': <pandas.core.groupby.DataFrameGroupBy object>, '__':           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], '___':      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, ...}\n        self.user_ns = {'DT': <module 'datetime' from '/usr/local/Cellar/pytho...ramework/Versions/3.5/lib/python3.5/datetime.py'>, 'In': ['', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'Cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', \"get_ipython().magic('load_ext Cython')\", 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%loa...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"%mat...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"impo...ot as plt\\\\nplt.style.use(\\'ggplot\\')\\\\nimport time\")', r\"get_ipython().run_cell_magic('cython', '', 'date...a x: (x.type == \\'National holiday\\'), axis=1)]')\", \"datesFrame = pd.read_csv('myDates.csv')\\ndatesFra...ambda x: (x.type == 'National holiday'), axis=1)]\", 'get_ipython().run_cell_magic(\\'cython\\', \\'\\', \"def ...n    return difference / np.timedelta64(1, \\'D\\')\")', \"get_ipython().magic('load_ext Cython')\", \"import pandas as pd\\nimport numpy as np\\nimport ma...pyplot as plt\\nplt.style.use('ggplot')\\nimport time\", \"datesFrame = pd.read_csv('myDates.csv')\\ndatesFra...ambda x: (x.type == 'National holiday'), axis=1)]\", \"def get_nearest_date(dates, pivot):\\n    nearest ...t)\\n    return difference / np.timedelta64(1, 'D')\", 'datesFrameSmall= datesFrame[: 10]', \"time1 = time.time()\\ndatesFrameSmall['daysBeforeH....3f ms' % ((time2-time1)*1000.0))\\ndatesFrameSmall\", \"# disabled - takes too long\\n#time1 = time.time()...k %0.3f ms' % ((time2-time1)*1000.0))\\n#datesFrame\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", r\"get_ipython().run_cell_magic('cython', '', '####...sses=num_cpus)  \\npool.map(process_fold, folds)')\", ...], 'Out': {15:      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, 20:           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], 25: <pandas.core.groupby.DataFrameGroupBy object>}, 'Parallel': <class 'joblib.parallel.Parallel'>, '_': <pandas.core.groupby.DataFrameGroupBy object>, '_15':      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, '_20':           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], '_25': <pandas.core.groupby.DataFrameGroupBy object>, '__':           myDates\n0      2014-09-01\n1      2014-...2-12\n178663 2015-02-12\n\n[178664 rows x 1 columns], '___':      myDates  daysBeforeHoliday  daysAfterHolida...9 2014-04-06               90.0              15.0, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\n/Users/geoHeil/Dropbox/masterThesis/thesis/researchCode/python/TMA/<ipython-input-28-24c5f514da83> in <module>()\n      9 def applyParallel(dfGrouped, func):\n     10     retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n     11     return pd.concat(retLst)\n     12 \n     13 print ('parallel version: ')\n---> 14 print( applyParallel(datesFrame.groupby(datesFrame.index), get_nearest_dateParallel))\n     15 \n     16 \n     17 \n     18 \n\n...........................................................................\n/Users/geoHeil/Dropbox/masterThesis/thesis/researchCode/python/TMA/<ipython-input-28-24c5f514da83> in applyParallel(dfGrouped=<pandas.core.groupby.DataFrameGroupBy object>, func=<function get_nearest_dateParallel>)\n      5     nearest = min(dates, key=lambda x: abs(x - pivot))\n      6     difference = abs(nearest - pivot)\n      7     return difference / np.timedelta64(1, 'D')\n      8 \n      9 def applyParallel(dfGrouped, func):\n---> 10     retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n     11     return pd.concat(retLst)\n     12 \n     13 print ('parallel version: ')\n     14 print( applyParallel(datesFrame.groupby(datesFrame.index), get_nearest_dateParallel))\n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=Parallel(n_jobs=8), iterable=<generator object applyParallel.<locals>.<genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=8)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Sat Sep  3 17:17:40 2016\nPID: 4494                Python 3.5.2: /usr/local/opt/python3/bin/python3.5\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in __call__(self=<joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function get_nearest_dateParallel>, (     myDates\n0 2014-09-01,), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/usr/local/lib/python3.5/site-packages/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function get_nearest_dateParallel>\n        args = (     myDates\n0 2014-09-01,)\n        kwargs = {}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\nTypeError: get_nearest_dateParallel() missing 1 required positional argument: 'pivot'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "def get_nearest_dateParallel(dates, pivot):\n",
    "    nearest = min(dates, key=lambda x: abs(x - pivot))\n",
    "    difference = abs(nearest - pivot)\n",
    "    return difference / np.timedelta64(1, 'D')\n",
    "\n",
    "def applyParallel(dfGrouped, func):\n",
    "    retLst = Parallel(n_jobs=multiprocessing.cpu_count())(delayed(func)(group) for name, group in dfGrouped)\n",
    "    return pd.concat(retLst)\n",
    "\n",
    "print ('parallel version: ')\n",
    "print( applyParallel(datesFrame.groupby(datesFrame.index), get_nearest_dateParallel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## approach 4 - pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "did not have too much time to look into that option. But if approach 3 works that looks much cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parallelize_dataframe(df, func):\n",
    "    df_split = np.array_split(df, num_partitions)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiply_columns(data):\n",
    "    data['length_of_word'] = data['species'].apply(lambda x: len(x))\n",
    "    return data\n",
    "    \n",
    "iris = parallelize_dataframe(iris, multiply_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
