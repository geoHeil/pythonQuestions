{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lightgbm categorical problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regular dataset has around 300k rows with around 3% positives of the binary target class. It consists of regular numeric columns, ordered categoricals encoded as 1,2,3 and factor variables which are dummy-coded. Only the ones which do not have a too large number of factors are used as factors for the dummy coding. The other ones are transformed into a numeric space e.g. by calculating a percentage of the target class contained in this factor variable. In total (after the dummy coding) there are a little bit less than 10k columns.\n",
    "\n",
    "Below I tried to generate a sample df, Howver did not (yet) succed.\n",
    "\n",
    "### skip the imports - please see the problem below. Finally I could reproduce it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from pylightgbm.models import GBMClassifier\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "_seed=49\n",
    "\n",
    "def transformToXy(data):\n",
    "    # Extract the data\n",
    "    X = data.drop(['NEVERPAYER'], axis=1)\n",
    "    # Extract the labels\n",
    "    y = data['NEVERPAYER']\n",
    "    return X, y\n",
    "\n",
    "def labelEncodeCategoricalData(df):\n",
    "    df_copy = df.copy()\n",
    "    cat_cols = df_copy.columns[df_copy.dtypes == 'category'].values\n",
    "    df_copy[cat_cols] = df_copy[cat_cols].apply(lambda x: x.cat.codes)\n",
    "    return df_copy\n",
    "\n",
    "class ColumnExtractor(TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def transform(self, X, *_):\n",
    "        # print('selecting columns ', self.columns)\n",
    "        return X[self.columns]\n",
    "\n",
    "    def fit(self, X, *_):\n",
    "        return self\n",
    "    \n",
    "#########################################################\n",
    "# Percentage transformer perform basic effects coding of categorical variables\n",
    "\n",
    "class PercentageTransformer(TransformerMixin):\n",
    "    def __init__(self, colname, typePercentage='totalTarget', _target='NEVERPAYER', _dropOriginal=True):\n",
    "        self.colname = colname\n",
    "        self._target = _target\n",
    "        self._dropOriginal = _dropOriginal\n",
    "        self.typePercentage = typePercentage\n",
    "\n",
    "    def fit(self, X, y, *_):\n",
    "        original = pd.concat([y, X], axis=1)\n",
    "        grouped = original.groupby([self.colname, self._target]).size()\n",
    "        if self.typePercentage == 'totalTarget':\n",
    "            df = grouped / original[self._target].sum()\n",
    "        else:\n",
    "            df = (grouped / grouped.groupby(level=0).sum())\n",
    "\n",
    "        if self.typePercentage == 'totalTarget':\n",
    "            nameCol = \"pre_\" + self.colname\n",
    "        else:\n",
    "            nameCol = \"pre2_\" + self.colname\n",
    "        self.nameCol = nameCol\n",
    "        grouped = df.reset_index(name=nameCol)\n",
    "        groupedOnly = grouped[grouped[self._target] == 1]\n",
    "        groupedOnly = groupedOnly.drop(self._target, 1)\n",
    "\n",
    "        self.result = groupedOnly\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataF):\n",
    "        mergedThing = pd.merge(dataF, self.result, on=self.colname, how='left')\n",
    "        mergedThing.loc[(mergedThing[self.nameCol].isnull()), self.nameCol] = 0\n",
    "        if self._dropOriginal:\n",
    "            mergedThing = mergedThing.drop(self.colname, 1)\n",
    "        return mergedThing\n",
    "\n",
    "\n",
    "class PercentageAllTransformer(TransformerMixin):\n",
    "    def __init__(self, columnsToTransform, _colBiasDrop=None, typePercentage='totalTarget', _target='NEVERPAYER',\n",
    "                 _dropOriginal=True):\n",
    "        print(\n",
    "            'WARN: mutually exclusive options: either _colBiasDrop is None and then _dropOriginal can be True or _colBiasDrop is set and _dropOriginal must be false')\n",
    "        self._target = _target\n",
    "        self._dropOriginal = _dropOriginal\n",
    "        self.typePercentage = typePercentage\n",
    "        self.transformers = {}\n",
    "        self.colsToBias = columnsToTransform\n",
    "        self._colBiasDrop = _colBiasDrop\n",
    "\n",
    "        logger.debug(\"colums to bias \" + str(self.colsToBias))\n",
    "        logger.debug(\"colums to drop \" + str(self._colBiasDrop))\n",
    "\n",
    "    def fit(self, X, y, *_):\n",
    "        if self._colBiasDrop is not None:\n",
    "            colToIterate = self.colsToBias.union(self._colBiasDrop)\n",
    "        else:\n",
    "            colToIterate = self.colsToBias\n",
    "        for col in colToIterate:\n",
    "            myTransf = PercentageTransformer(col, typePercentage=self.typePercentage, _target=self._target,\n",
    "                                             _dropOriginal=False)  # deliberately set to False to enable multi-drop\n",
    "            self.transformers[col] = myTransf.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        logger.info('percentage transforming cols')\n",
    "        transformed = None\n",
    "        for col in self.colsToBias:\n",
    "            if transformed is None:\n",
    "                transformed = self.transformers[col].transform(X)\n",
    "            else:\n",
    "                intermediate = self.transformers[col].transform(X)\n",
    "                if self.typePercentage == 'totalTarget':\n",
    "                    intermediate = intermediate[['pre_' + col]]\n",
    "                else:\n",
    "                    intermediate = intermediate[['pre2_' + col]]\n",
    "                transformed = pd.concat([transformed, intermediate], axis=1)\n",
    "        if self._dropOriginal:\n",
    "            transformed = transformed.drop(self.colsToBias, axis=1)\n",
    "        if self._colBiasDrop is not None:\n",
    "            transformed = transformed.drop(self._colBiasDrop, axis=1)\n",
    "        return transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 11)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetdf = pd.DataFrame(np.random.randint(0,2,(100000,1)),columns=['NEVERPAYER'])\n",
    "XDF = pd.DataFrame(np.random.randint(0,100,(1000000,10)),columns=list('ABCDEFGHIJ'))\n",
    "mydf = pd.concat([targetdf, XDF], join='inner', axis=1)\n",
    "\n",
    "mydf['A'] = mydf['A'].astype('category')\n",
    "mydf['B'] = mydf['B'].astype('category')\n",
    "mydf['C'] = mydf['C'].astype('category')\n",
    "mydf['D'] = mydf['D'].astype('category')\n",
    "\n",
    "mydf.loc[(mydf.E < 50), 'E_smaller50_only01'] = 1\n",
    "mydf['E_smaller50_only01'] = mydf['E_smaller50_only01'].fillna(0)\n",
    "\n",
    "#mydf = pd.get_dummies(mydf, sparse=False)\n",
    "X, y = transformToXy(mydf)\n",
    "\n",
    "CONTINUOUS_FIELDS = X.select_dtypes(include=['number']).columns  # includes orderd factors\n",
    "FACTOR_FIELDS = X.select_dtypes(include=['category']).columns\n",
    "FACTOR_FIELDS = X.select_dtypes(include=['category']).columns\n",
    "columnsToDrop = ['C'] # chosen randomly, however in the real dataset \n",
    "columnsToBias_keep = FACTOR_FIELDS[~FACTOR_FIELDS.isin(columnsToDrop)]\n",
    "#these columns must be bias-coded. Otherwise the dataframe is blown up too big by dummy coding\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_original = X.copy()\n",
    "X = labelEncodeCategoricalData(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: mutually exclusive options: either _colBiasDrop is None and then _dropOriginal can be True or _colBiasDrop is set and _dropOriginal must be false\n",
      "WARN: mutually exclusive options: either _colBiasDrop is None and then _dropOriginal can be True or _colBiasDrop is set and _dropOriginal must be false\n"
     ]
    }
   ],
   "source": [
    "pathToLightGBM = '~/neverpayer/lightgbm'\n",
    "clf = GBMClassifier(exec_path=pathToLightGBM, \n",
    "                              num_iterations=100, learning_rate=0.1,\n",
    "                              num_leaves=2000, min_data_in_leaf=100, metric='binary_logloss',\n",
    "                              feature_fraction=0.7, bagging_fraction=0.7, bagging_freq=0,\n",
    "                              metric_freq=1, early_stopping_round=20,\n",
    "                             tree_learner=\"serial\", num_threads=4,\n",
    "                              is_unbalance=False)\n",
    "\n",
    "prediction_pipe = Pipeline([\n",
    "        ('extract', ColumnExtractor(FACTOR_FIELDS)),\n",
    "        ('bias1', PercentageAllTransformer(columnsToBias_keep.union(columnsToDrop), _colBiasDrop=None,\n",
    "                                          _dropOriginal=False, typePercentage='totalTarget')),\n",
    "         ('bias2',\n",
    "         PercentageAllTransformer(columnsToBias_keep, _colBiasDrop=columnsToDrop, _dropOriginal=False,\n",
    "                                  typePercentage='groupwise')),\n",
    "        ('one_hot', OneHotEncoder(sparse=False, handle_unknown='ignore')),\n",
    "        ('estimator', clf)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## error\n",
    "as you can see this results in columns which contain only few values as they are binary encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Loading parameters .. finished\n",
      "[LightGBM] [Error] Feature Column_300 only contains one value, will be ignored\n",
      "[LightGBM] [Error] Feature Column_301 only contains one value, will be ignored\n",
      "[LightGBM] [Error] Feature Column_302 only contains one value, will be ignored\n",
      "[LightGBM] [Error] Feature Column_303 only contains one value, will be ignored\n",
      "[LightGBM] [Error] Feature Column_304 only contains one value, will be ignored\n",
      "[LightGBM] [Error] Feature Column_305 only contains one value, will be ignored\n",
      "[LightGBM] [Error] Feature Column_306 only contains one value, will be ignored\n",
      "[LightGBM] [Info] Finish loading data, use 0.569019 seconds\n",
      "[LightGBM] [Info] Number of postive:40188,  number of negative:39812\n",
      "[LightGBM] [Info] Number of data:80000, Number of features:300\n",
      "[LightGBM] [Info] Finish training initilization.\n",
      "[LightGBM] [Info] Start train ...\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 0.065842 seconds elapsed, finished 1 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 0.135476 seconds elapsed, finished 2 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 0.203043 seconds elapsed, finished 3 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 0.267127 seconds elapsed, finished 4 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 0.330565 seconds elapsed, finished 5 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=196\n",
      "[LightGBM] [Info] 0.405848 seconds elapsed, finished 6 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 0.469099 seconds elapsed, finished 7 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 0.532845 seconds elapsed, finished 8 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 0.595683 seconds elapsed, finished 9 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 0.669941 seconds elapsed, finished 10 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 0.733718 seconds elapsed, finished 11 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 0.795884 seconds elapsed, finished 12 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 0.859927 seconds elapsed, finished 13 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 0.927451 seconds elapsed, finished 14 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 0.989541 seconds elapsed, finished 15 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 1.053046 seconds elapsed, finished 16 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 1.122726 seconds elapsed, finished 17 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 1.191436 seconds elapsed, finished 18 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=195\n",
      "[LightGBM] [Info] 1.254803 seconds elapsed, finished 19 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 1.317836 seconds elapsed, finished 20 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=202\n",
      "[LightGBM] [Info] 1.380637 seconds elapsed, finished 21 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=202\n",
      "[LightGBM] [Info] 1.449516 seconds elapsed, finished 22 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 1.512874 seconds elapsed, finished 23 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 1.575224 seconds elapsed, finished 24 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 1.639456 seconds elapsed, finished 25 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 1.707811 seconds elapsed, finished 26 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 1.771714 seconds elapsed, finished 27 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 1.835096 seconds elapsed, finished 28 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 1.897938 seconds elapsed, finished 29 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 1.965543 seconds elapsed, finished 30 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=196\n",
      "[LightGBM] [Info] 2.028992 seconds elapsed, finished 31 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 2.092650 seconds elapsed, finished 32 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 2.156298 seconds elapsed, finished 33 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=202\n",
      "[LightGBM] [Info] 2.225972 seconds elapsed, finished 34 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 2.289378 seconds elapsed, finished 35 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 2.352665 seconds elapsed, finished 36 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 2.415744 seconds elapsed, finished 37 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 2.485456 seconds elapsed, finished 38 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 2.549179 seconds elapsed, finished 39 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=195\n",
      "[LightGBM] [Info] 2.614260 seconds elapsed, finished 40 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 2.677249 seconds elapsed, finished 41 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 2.745667 seconds elapsed, finished 42 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 2.808094 seconds elapsed, finished 43 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 2.871106 seconds elapsed, finished 44 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 2.935202 seconds elapsed, finished 45 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 3.003209 seconds elapsed, finished 46 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 3.067941 seconds elapsed, finished 47 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 3.133267 seconds elapsed, finished 48 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 3.196302 seconds elapsed, finished 49 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 3.265826 seconds elapsed, finished 50 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 3.329301 seconds elapsed, finished 51 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 3.391720 seconds elapsed, finished 52 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 3.455528 seconds elapsed, finished 53 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 3.524546 seconds elapsed, finished 54 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 3.587191 seconds elapsed, finished 55 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 3.649866 seconds elapsed, finished 56 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 3.713830 seconds elapsed, finished 57 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 3.782624 seconds elapsed, finished 58 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 3.846016 seconds elapsed, finished 59 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 3.908534 seconds elapsed, finished 60 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=202\n",
      "[LightGBM] [Info] 3.971547 seconds elapsed, finished 61 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 4.039900 seconds elapsed, finished 62 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 4.105497 seconds elapsed, finished 63 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 4.168187 seconds elapsed, finished 64 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 4.232236 seconds elapsed, finished 65 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 4.300852 seconds elapsed, finished 66 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 4.363812 seconds elapsed, finished 67 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 4.427838 seconds elapsed, finished 68 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 4.492588 seconds elapsed, finished 69 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 4.564047 seconds elapsed, finished 70 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 4.627926 seconds elapsed, finished 71 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 4.692784 seconds elapsed, finished 72 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 4.755035 seconds elapsed, finished 73 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=196\n",
      "[LightGBM] [Info] 4.823347 seconds elapsed, finished 74 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 4.887202 seconds elapsed, finished 75 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 4.951206 seconds elapsed, finished 76 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 5.014525 seconds elapsed, finished 77 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 5.084396 seconds elapsed, finished 78 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=202\n",
      "[LightGBM] [Info] 5.148193 seconds elapsed, finished 79 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 5.212000 seconds elapsed, finished 80 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 5.275015 seconds elapsed, finished 81 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 5.343850 seconds elapsed, finished 82 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 5.407780 seconds elapsed, finished 83 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 5.471098 seconds elapsed, finished 84 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 5.534061 seconds elapsed, finished 85 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 5.602752 seconds elapsed, finished 86 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 5.666214 seconds elapsed, finished 87 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 5.729571 seconds elapsed, finished 88 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 5.792725 seconds elapsed, finished 89 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=196\n",
      "[LightGBM] [Info] 5.859587 seconds elapsed, finished 90 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 5.922872 seconds elapsed, finished 91 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 5.985684 seconds elapsed, finished 92 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 6.049151 seconds elapsed, finished 93 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 6.120155 seconds elapsed, finished 94 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 6.183677 seconds elapsed, finished 95 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=197\n",
      "[LightGBM] [Info] 6.245798 seconds elapsed, finished 96 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=201\n",
      "[LightGBM] [Info] 6.308978 seconds elapsed, finished 97 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=200\n",
      "[LightGBM] [Info] 6.379199 seconds elapsed, finished 98 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=198\n",
      "[LightGBM] [Info] 6.444646 seconds elapsed, finished 99 iteration\n",
      "[LightGBM] [Info] cannot find more split with gain = -inf , current #leaves=199\n",
      "[LightGBM] [Info] 6.507551 seconds elapsed, finished 100 iteration\n",
      "[LightGBM] [Info] Finished train\n",
      "\n",
      "[LightGBM] [Info] Loading parameters .. finished\n",
      "[LightGBM] [Info] 100 models has been loaded\n",
      "\n",
      "[LightGBM] [Info] Finish predict initilization.\n",
      "[LightGBM] [Info] Finish predict.\n",
      "\n",
      "found x number of positive class labels  10592\n"
     ]
    }
   ],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=_seed)\n",
    "for train_index, test_index in split.split(X, y):\n",
    "    X_train = X.iloc[train_index]\n",
    "    X_test = X.iloc[test_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "    \n",
    "    prediction_pipe.fit(X_train, y_train)\n",
    "    y_predicted = prediction_pipe.predict(X_test)\n",
    "    print('found x number of positive class labels ', y_predicted.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A deeper look at the columns\n",
    "why are features ignored?\n",
    " \n",
    " > [LightGBM] [Error] Feature Column_300 only contains one value, will be ignored\n",
    "[LightGBM] [Error] Feature Column_301 only contains one value, will be ignored\n",
    "[LightGBM] [Error] Feature Column_302 only contains one value, will be ignored\n",
    "[LightGBM] [Error] Feature Column_303 only contains one value, will be ignored\n",
    "[LightGBM] [Error] Feature Column_304 only contains one value, will be ignored\n",
    "[LightGBM] [Error] Feature Column_305 only contains one value, will be ignored\n",
    "[LightGBM] [Error] Feature Column_306 only contains one value, will be ignored\n",
    "## look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'E_smaller50_only01'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A                     category\n",
       "B                     category\n",
       "C                     category\n",
       "D                     category\n",
       "E                        int64\n",
       "F                        int64\n",
       "G                        int64\n",
       "H                        int64\n",
       "I                        int64\n",
       "J                        int64\n",
       "E_smaller50_only01     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_original.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bias coding\n",
    "as some levels are huge > 100 I use percentage based bias coding to reduce the levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'C', 'D'], dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FACTOR_FIELDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['A', 'B', 'D'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsToBias_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsToDrop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: mutually exclusive options: either _colBiasDrop is None and then _dropOriginal can be True or _colBiasDrop is set and _dropOriginal must be false\n",
      "WARN: mutually exclusive options: either _colBiasDrop is None and then _dropOriginal can be True or _colBiasDrop is set and _dropOriginal must be false\n"
     ]
    }
   ],
   "source": [
    "codingPipe = Pipeline([\n",
    "        ('bias1', PercentageAllTransformer(columnsToBias_keep.union(columnsToDrop), _colBiasDrop=None,\n",
    "                                          _dropOriginal=False, typePercentage='totalTarget')),\n",
    "         ('bias2',\n",
    "         PercentageAllTransformer(columnsToBias_keep, _colBiasDrop=columnsToDrop, _dropOriginal=False,\n",
    "                                  typePercentage='groupwise')),\n",
    "    ])\n",
    "codingPipe.fit(X,y)\n",
    "X = codingPipe.transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as you can see some additional columns are generated\n",
    "- one for biasCol for type1\n",
    "- one per biasCol for type2\n",
    "- as biasCol have a maximum of X levels << 1k we additionally dummy-code the variables\n",
    "- but there are variables like `C`which have >1k levels. These should be retained as `pre_C` shows, but the initial `C` column is dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "      <th>E_smaller50_only01</th>\n",
       "      <th>pre_A</th>\n",
       "      <th>pre_B</th>\n",
       "      <th>pre_C</th>\n",
       "      <th>pre_D</th>\n",
       "      <th>pre2_A</th>\n",
       "      <th>pre2_B</th>\n",
       "      <th>pre2_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86</td>\n",
       "      <td>86</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>19</td>\n",
       "      <td>54</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>0.009894</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.010212</td>\n",
       "      <td>0.491756</td>\n",
       "      <td>0.501514</td>\n",
       "      <td>0.504425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>45</td>\n",
       "      <td>30</td>\n",
       "      <td>48</td>\n",
       "      <td>35</td>\n",
       "      <td>82</td>\n",
       "      <td>71</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.009436</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>0.010272</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.486653</td>\n",
       "      <td>0.515759</td>\n",
       "      <td>0.536729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17</td>\n",
       "      <td>85</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>27</td>\n",
       "      <td>65</td>\n",
       "      <td>39</td>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010093</td>\n",
       "      <td>0.009356</td>\n",
       "      <td>0.011008</td>\n",
       "      <td>0.010013</td>\n",
       "      <td>0.511604</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.521244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>33</td>\n",
       "      <td>22</td>\n",
       "      <td>44</td>\n",
       "      <td>55</td>\n",
       "      <td>18</td>\n",
       "      <td>48</td>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.010232</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.009814</td>\n",
       "      <td>0.501463</td>\n",
       "      <td>0.503539</td>\n",
       "      <td>0.518947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>25</td>\n",
       "      <td>87</td>\n",
       "      <td>10</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>33</td>\n",
       "      <td>80</td>\n",
       "      <td>47</td>\n",
       "      <td>58</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010192</td>\n",
       "      <td>0.009615</td>\n",
       "      <td>0.009038</td>\n",
       "      <td>0.009794</td>\n",
       "      <td>0.519270</td>\n",
       "      <td>0.479167</td>\n",
       "      <td>0.502041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A   B   D   E   F   G   H   I   J  E_smaller50_only01     pre_A     pre_B  \\\n",
       "0  86  86  28   1   9  48  19  54  48                 1.0  0.010093  0.009894   \n",
       "1  28  28  45  30  48  35  82  71  35                 1.0  0.009436  0.010749   \n",
       "2  17  85  12   5  12  27  65  39   8                 1.0  0.010093  0.009356   \n",
       "3  26  33  22  44  55  18  48  60  49                 1.0  0.010232  0.009913   \n",
       "4  25  87  10  61  53  33  80  47  58                 0.0  0.010192  0.009615   \n",
       "\n",
       "      pre_C     pre_D    pre2_A    pre2_B    pre2_D  \n",
       "0  0.010212  0.010212  0.491756  0.501514  0.504425  \n",
       "1  0.010272  0.010909  0.486653  0.515759  0.536729  \n",
       "2  0.011008  0.010013  0.511604  0.500000  0.521244  \n",
       "3  0.009834  0.009814  0.501463  0.503539  0.518947  \n",
       "4  0.009038  0.009794  0.519270  0.479167  0.502041  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now dummycoding should be performed on the remaining categorical variables of A,B,D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0    99003\n",
       "1.0      997\n",
       "Name: 0, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onehot = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "onehot.fit(X[['A', 'B']])\n",
    "onehotres = onehot.transform(X[['A', 'B']])\n",
    "print(onehotres)\n",
    "onehotres = pd.DataFrame(onehotres)\n",
    "onehotres[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which results in only 0's and 1es being present in the column"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
